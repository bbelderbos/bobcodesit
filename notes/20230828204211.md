# Speed up repetitive function calls with caching üí°

If a function is often called with the same arguments and the computation is expensive, caching the results can provide a performance boost.

Here's how:

1Ô∏è‚É£ Your regular function:

```
def compute(x, y):
    # Some expensive computation
    return x * y
```

2Ô∏è‚É£ Transform it with caching:

```
from functools import lru_cache

@lru_cache  # Defaults to maxsize=128
def compute(x, y):
    return x * y
```

3Ô∏è‚É£ Use it!

When compute is called with the same arguments, the cached result will be returned instead of recomputing.

```
print(compute(2, 3))  # Computed
print(compute(2, 3))  # Cached!
```

üìå Bonus:

‚Ä¢ lru_cache has an optional maxsize parameter which limits the number of stored results. When full, older results are discarded.

For an unbounded cache, use `@lru_cache(maxsize=None)`.

‚Ä¢ To view cache stats, you can use the cache_info() method: compute.cache_info()

E.g.

```
# Some calls to populate the cache
compute(1, 2)
compute(2, 3)
compute(1, 2)  # This is a cache hit

info = compute.cache_info() print(info)
# Outputs: CacheInfo(hits=1, misses=2, maxsize=128, currsize=2)
```

‚Ä¢ If you need to clear the cache for some reason, use the cache_clear() method: compute.cache_clear()

```
compute.cache_clear()

info_after_clear = compute.cache_info()
print(info_after_clear)  # Outputs: CacheInfo(hits=0, misses=0, maxsize=128, currsize=0)
```

#functools #caching #memoization
