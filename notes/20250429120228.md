# Detect

The *chardet* library is super handy for guessing unknown file encodings.

As an experiment, let's write a Latin-1 encoded string to a file:

```
text = "Olá, ¿cómo está? München"
with open('file.txt', 'w', encoding='latin-1') as f:
    f.write(text)
```

If we now try to open it as UTF-8:

```
with open('file.txt', encoding='utf-8') as f:
    content = f.read()
    print(content)
```

we get:

```
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 2: invalid continuation byte
```

_chardet_ to the rescue:

```
# /// script
# dependencies = [
#   "chardet",
# ]
# ///
import chardet

text = "Olá, ¿cómo está? München"
with open('file.txt', 'w', encoding='latin-1') as f:
    f.write(text)


with open('file.txt', 'rb') as f:
    raw = f.read()

print(chardet.detect(raw))
# {'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}
```

(Note: the inline metadata lets uv install the dependency automatically.)

Now using the detected encoding:

```
with open('file.txt', encoding='ISO-8859-1') as f:
    content = f.read()
    print(content)j

# Olá, ¿cómo está? München
```

#encoding #chardet
