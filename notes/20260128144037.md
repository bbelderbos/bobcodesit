# Reliable CI Benchmarks with pytest-codspeed

Traditional CI benchmarks are noisy (10-30% variance) because they measure wall-clock time. CodSpeed uses CPU instruction simulation instead, giving you <1% variance—so you can actually trust the results.

```python
import pytest

@pytest.mark.benchmark
def test_my_algorithm(benchmark):
    data = list(range(1000))
    result = benchmark(my_algorithm, data)
    assert result is not None
```

Run locally with `pytest` (wall-clock), in CI with `pytest --codspeed` (CPU simulation). The `--codspeed` flag only works in their CI environment—that's by design.

Gotcha: push to `main` first to establish a baseline before creating PRs.

#performance #ci #pytest
